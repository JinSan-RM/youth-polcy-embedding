services:
  BE:
    container_name: BE
    build:
      context: ./BE
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - PYTHONUNBUFFERED=1
      - DATABASE_URL=postgresql://postgres:password@db:5432/youth_policy_embedding
      - API_KEY=
    networks:
      - service_network

  FE:
    container_name: FE
    build:
      context: ./FE
      dockerfile: Dockerfile
    ports:
      - "3000:80"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
    networks:
      - service_network

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    build:
      context: ./ollama
      dockerfile: Dockerfile
    ports:
      - "11434:11434"
    volumes:
      - ./models:/models
    environment:
      - OLLAMA_API_PORT=11434
      - OLLAMA_HOST=0.0.0.0:11434
      - CUDA_VISIBLE_DEVICES=0  # GPU 0번만 사용
      - TF_FORCE_GPU_ALLOW_GROWTH=true  # 메모리 동적 할당
    networks:
      - service_network
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: 1
            capabilities: [gpu]
  networks:
    service_network:
      driver: bridge
      ipam:
        config:
          - subnet: 172.19.0.0/16
